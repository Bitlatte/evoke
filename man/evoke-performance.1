'\" t
.\" Automatically generated by Pandoc 3.7.0.2
.\"
.TH "" "" "" ""
.SH Performance
Evoke is engineered from the ground up for speed and efficiency,
ensuring that your site builds quickly without monopolizing system
resources.
This is accomplished through a combination of a lightweight
architecture, efficient algorithms, and the inherent performance of the
Go programming language.
.SS The Go Advantage
Evoke is written in Go, a language celebrated for its performance and
concurrency.
This choice provides several key advantages:
.IP \(bu 2
\f[B]Single Binary Deployment:\f[R] Evoke compiles to a single,
self\-contained binary.
This means there are no external dependencies to install or manage,
making it incredibly fast to deploy and execute.
.IP \(bu 2
\f[B]Built\-in Concurrency:\f[R] Go\(cqs goroutines and channels provide
a powerful and efficient model for concurrency.
Evoke leverages this to parallelize tasks and maximize the use of
available CPU cores.
.SS Core Performance Features
.SS High\-Throughput Build Process
Evoke\(cqs build process is designed for maximum throughput.
Here are some of the key features that make it so fast:
.IP \(bu 2
\f[B]Parallel File Processing:\f[R] Evoke processes your content files
in parallel, taking full advantage of multi\-core processors to
dramatically reduce build times.
It creates a pool of workers, with one worker per CPU core, to ensure
that your site is built as quickly as possible.
.IP \(bu 2
\f[B]In\-Memory Caching:\f[R] Layouts and templates are parsed once and
then cached in memory.
This avoids redundant file I/O and parsing operations, resulting in a
significant speed boost.
The cache is implemented using a \f[CR]sync.Map\f[R], which is optimized
for concurrent access.
.IP \(bu 2
\f[B]Efficient Memory Management:\f[R] Evoke is designed to be light on
memory usage.
We use a \f[CR]sync.Pool\f[R] to reuse memory buffers for file I/O and
content processing.
This reduces the number of memory allocations and the pressure on the
garbage collector, leading to faster and more consistent build times.
.IP \(bu 2
\f[B]Singleton Parsers:\f[R] The Goldmark Markdown parser is initialized
only once and then reused for all Markdown files.
This avoids the significant overhead of creating a new parser for each
file.
.SS The Plugin System and Performance
Evoke\(cqs plugin system is designed to be flexible and powerful, but
it\(cqs important to be aware of the performance implications of the
plugins you use.
While the core of Evoke is highly optimized, a poorly written plugin can
slow down your build.
.PP
Here are some things to keep in mind when writing or using plugins:
.IP \(bu 2
\f[B]Plugin Hooks:\f[R] Plugins can \(lqhook\(rq into various stages of
the build process.
Be mindful of the hooks you use and the work you do in them.
For example, a heavy computation in a hook that runs for every file can
have a significant impact on build times.
.IP \(bu 2
\f[B]Memory Allocations:\f[R] Be mindful of memory allocations in your
plugins.
If you need to work with large amounts of data, consider using a
\f[CR]sync.Pool\f[R] to reuse buffers, just like Evoke does internally.
.IP \(bu 2
\f[B]Caching:\f[R] If your plugin performs expensive operations,
consider implementing your own caching layer to avoid redundant work.
.SS Benchmark Results
To provide a transparent look at our performance, we\(cqve included the
results from our benchmark tests.
These tests were run on an Apple M1 CPU and measure the performance of
key components in the Evoke ecosystem.
.PP
The following metrics are used:
.IP \(bu 2
\f[CR]ns/op\f[R]: The average time each operation takes in nanoseconds.
Lower is better.
.IP \(bu 2
\f[CR]B/op\f[R]: The average number of bytes allocated per operation.
Lower is better.
.IP \(bu 2
\f[CR]allocs/op\f[R]: The average number of memory allocations per
operation.
Lower is better.
.SS Build (\f[CR]pkg/build\f[R])
This benchmark measures the time it takes to build a site with 100 pages
from scratch.
This includes loading plugins, copying public assets, processing
content, and running all associated hooks.
It provides a holistic view of the site generation time.
.RS
.PP
\f[B]Note:\f[R] The clean build is now slower than it was previously.
This is because Evoke now builds a dependency graph and hashes all of
your files to enable incremental builds.
While the initial build is slower, subsequent builds will be
significantly faster.
.RE
.PP
.TS
tab(@);
l l l l.
T{
Benchmark
T}@T{
Time/op (ms)
T}@T{
Memory/op (MB)
T}@T{
Allocations/op
T}
_
T{
BenchmarkBuild
T}@T{
46.15
T}@T{
7.62
T}@T{
31283
T}
.TE
.SS Pipelines (\f[CR]pkg/pipelines\f[R])
These benchmarks measure the time it takes for each content pipeline to
process a realistic piece of content.
.PP
.TS
tab(@);
lw(17.5n) lw(8.4n) lw(9.8n) lw(9.8n) lw(24.5n).
T{
Benchmark
T}@T{
Time/op (ms)
T}@T{
Memory/op (KB)
T}@T{
Allocations/op
T}@T{
Notes
T}
_
T{
BenchmarkMarkdownPipeline
T}@T{
0.15
T}@T{
111.13
T}@T{
429
T}@T{
Processes a 100\-paragraph MD file
T}
T{
BenchmarkHTMLPipeline
T}@T{
0.01
T}@T{
32.34
T}@T{
8
T}@T{
Processes a 100\-paragraph HTML file
T}
T{
BenchmarkCopyPipeline
T}@T{
0.12
T}@T{
1048.63
T}@T{
2
T}@T{
Processes a 1MB file
T}
.TE
.SS Partials (\f[CR]pkg/partials\f[R])
This benchmark measures the time it takes to load and parse 50 partial
templates from the \f[CR]partials\f[R] directory.
.PP
.TS
tab(@);
lw(24.1n) lw(13.8n) lw(16.1n) lw(16.1n).
T{
Benchmark
T}@T{
Time/op (ms)
T}@T{
Memory/op (KB)
T}@T{
Allocations/op
T}
_
T{
BenchmarkLoadPartials
T}@T{
2.24
T}@T{
246.05
T}@T{
2148
T}
.TE
.SS Plugins (\f[CR]pkg/plugins\f[R])
This benchmark measures the overhead of the plugin system by sending a
10KB payload over gRPC.
.PP
.TS
tab(@);
l l l l.
T{
Benchmark
T}@T{
Time/op (ms)
T}@T{
Memory/op (KB)
T}@T{
Allocations/op
T}
_
T{
BenchmarkPlugin
T}@T{
0.10
T}@T{
76.10
T}@T{
187
T}
.TE
.SS Util (\f[CR]pkg/util\f[R])
These benchmarks measure the performance of common file system
operations.
.PP
.TS
tab(@);
lw(16.6n) lw(9.0n) lw(10.5n) lw(10.5n) lw(23.3n).
T{
Benchmark
T}@T{
Time/op (ms)
T}@T{
Memory/op (MB)
T}@T{
Allocations/op
T}@T{
Notes
T}
_
T{
BenchmarkCopyFile
T}@T{
0.96
T}@T{
0.03
T}@T{
10
T}@T{
Copies a 1MB file
T}
T{
BenchmarkCopyDirectory
T}@T{
14.06
T}@T{
2.43
T}@T{
1603
T}@T{
Copies a directory with 100+ files
T}
.TE
.SS Comparative Analysis
To provide a clear picture of how Evoke stacks up against other popular
static site generators, we conducted a comparative analysis with Hugo,
Eleventy, and Gatsby.
The following benchmarks were run on a test site with 5,000 markdown
files.
.PP
The test was conducted on an Apple M1 CPU.
Each project was set up with a basic configuration, and the build time
was measured using the \f[CR]time\f[R] command.
.PP
.TS
tab(@);
l l l l.
T{
SSG
T}@T{
Build Time (real)
T}@T{
Time Difference
T}@T{
Times Slower
T}
_
T{
Evoke
T}@T{
1.50s
T}@T{
\-
T}@T{
\-
T}
T{
Hugo
T}@T{
4.453s
T}@T{
+2.953s
T}@T{
2.97x
T}
T{
Eleventy
T}@T{
4.650s
T}@T{
+3.15s
T}@T{
3.10x
T}
T{
Gatsby
T}@T{
22.432s
T}@T{
+20.932s
T}@T{
14.95x
T}
.TE
.PP
As the results show, Evoke is significantly faster than the other static
site generators in this test case.
This is a testament to Evoke\(cqs lightweight architecture and efficient
design.
While this benchmark is not exhaustive, it provides a strong indication
of Evoke\(cqs performance advantages for content\-heavy sites.
.SS Summary
Evoke\(cqs commitment to performance means you can iterate on your site
more quickly and spend less time waiting for builds.
We are continuously working to make Evoke even faster and more
efficient, and we encourage our community to adopt
performance\-conscious practices when developing plugins.
